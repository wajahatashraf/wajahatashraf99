# Hi there ğŸ‘‹, Iâ€™m Wajahat Ashraf

**Computer Engineering Student | Data Science & Automation Enthusiast | Cloud Developer**

![Python](https://img.shields.io/badge/Python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=FF9900)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Elasticsearch](https://img.shields.io/badge/Elasticsearch-005571?style=for-the-badge&logo=elasticsearch&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)
![Web Scraping](https://img.shields.io/badge/Web_Scraping-FF6F61?style=for-the-badge&logo=python&logoColor=white)

---



ğŸ”­ Currently working at **Zoneomics**, where I specialize in scraping, processing, and managing complex zoning, parcel, and permit datasets with scalable pipelines.

---

## About Me

I build **automated data pipelines** and tools to extract, process, and visualize large-scale datasets from complex and protected web sources. I enjoy turning raw data into actionable insights using **Python, SQL, AWS, and modern data engineering practices**.  

- Extract data from websites with advanced scraping techniques.  
- Maintain automated CI/CD pipelines for **PostgreSQL â†’ Elasticsearch** sync.  
- Build tools for **Google Docs integration** with APIs for real-time data.  
- Develop scalable, cloud-deployed solutions using **AWS EC2, S3, and Elastic Beanstalk**.  

---

## ğŸ›  Skills

**Languages:** Python, C++, Java, SQL, JavaScript, HTML/CSS  
**Frameworks & Libraries:** Flask, Pandas, NumPy, Matplotlib, Seaborn, TensorFlow, OpenCV, Scrapy, Selenium  
**Databases & Tools:** PostgreSQL, Elasticsearch, PostGIS, PgAdmin, Docker, Git, Jenkins  
**Cloud & DevOps:** AWS (EC2, S3, Elastic Beanstalk), CI/CD pipelines, Docker, GitHub Actions  

---

## ğŸ” What I Do at Zoneomics

- Scrape complex layers: **zoning, parcels, permits** from websites with non-standard formats.  
- Maintain pipelines for inserting and syncing data from **PostgreSQL â†’ Elasticsearch**.  
- Build **Google Docs macros** integrated with our API to display live data.  
- Ensure high performance and scalability with **CI/CD pipelines, Docker, and AWS deployments**.  
- Work on other private pipelines and internal tools (not publicly shareable).  

---

## ğŸ“ˆ Projects & Contributions

### Public Projects

- **[ThinkGIS Scraper](https://github.com/wajahatashraf/ThinkGIS_Scaper)**  
 Scarpe different layers from ThinkGIS website with a user-friendly UI.  

- **[Beacon Scraper](https://github.com/wajahatashraf/beacon_scraper)**  
  Scrapes zoning and parcel layers from websites without a UI.  

- **[Google Docs Macro](https://github.com/wajahatashraf/Google-Docs-Marco)**  
  Integrates with APIs to display live zoning and parcel data in Google Docs.  

### Private/Internal Work

- Automated pipelines for large-scale **parcel and zoning data ingestion** (proprietary).  
- CI/CD pipelines for data processing and syncing **PostgreSQL â†’ Elasticsearch** (internal).  

---


## ğŸ“œ Certifications

- **[Generative AI: Introduction & Applications](https://www.coursera.org/account/accomplishments/verify/BBEF8BWT2Z1K)** â€“ IBM/Coursera  
- **[Advanced Data Structures, RSA & Quantum Algorithms](https://www.coursera.org/account/accomplishments/verify/8MC4DBZ2TSN0)** â€“ University of Colorado Boulder/Coursera  
- **AWS Cloud Practitioner Certification** â€“ AWS Training & Certification  
- **[Python Programming for Data Science, AI & Development](https://www.coursera.org/account/accomplishments/verify/AZ28U5FMYFY9)** â€“ IBM/Coursera  


---

## ğŸ“„ View My CV

[Download/View My CV](https://drive.google.com/file/d/14KY_Z--hn5AO26wpd9WD28cxUHF_3QpZ/view?usp=drive_link)  

---

## ğŸ“« Connect with Me

- ğŸ“§ wajahatashraf420@gmail.com  
- ğŸ”— [LinkedIn](https://www.linkedin.com/in/wajahatashraf99)  
- ğŸ’» [GitHub](https://github.com/wajahatashraf99)  

---

## âš¡ Fun Fact

I love **turning messy datasets into clean, actionable data pipelines**, and exploring **AI, cloud, and automation technologies**.  

---

